{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from groq import Groq\n",
    "import os\n",
    "from typing import Dict\n",
    "\n",
    "os.environ[\"GROQ_API_KEY\"] = \"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\"\n",
    "\n",
    "client = Groq(api_key=os.getenv(\"GROQ_API_KEY\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "json_file_path = 'datasets/patient_records1.json'\n",
    "\n",
    "with open(json_file_path, 'r', encoding='utf-8') as file:\n",
    "    test_data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def groq_pipeline_exists_nl(patient_record: str, semantic_regex_task: str, model: str = \"qwen-2.5-32b\") -> bool:\n",
    "    prompt = f\"\"\"\n",
    "    Patient Data (Natural Language):\n",
    "    {patient_record}\n",
    "\n",
    "    Context:\n",
    "    Extract semantic symbols from the provided patient data and determine if a match exists.\n",
    "\n",
    "    Task:\n",
    "    Determine whether at least one match of the following semantic regex is implied or explicitly present in the patient data above.\n",
    "\n",
    "    Semantic Regex:\n",
    "    {semantic_regex_task}\n",
    "\n",
    "    Return exactly one word: \"True\" or \"False\".\n",
    "    \"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You strictly answer True or False based on patient data and provided semantic regex matching.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=0.0,\n",
    "        max_tokens=5,\n",
    "        top_p=1,\n",
    "        stream=False,\n",
    "        stop=None,\n",
    "    )\n",
    "\n",
    "    result = response.choices[0].message.content.strip().lower()\n",
    "\n",
    "    return result == \"true\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating data: 100%|██████████| 20/20 [00:07<00:00,  2.57it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "predictions = []\n",
    "labels = []\n",
    "\n",
    "for item in tqdm(test_data, desc=\"Evaluating data\"):\n",
    "    patient_record = item[\"record\"]\n",
    "    semantic_regex = item[\"s_regex\"]\n",
    "    true_label = item[\"match\"]\n",
    "    \n",
    "    pred = groq_pipeline_exists_nl(\n",
    "        patient_record=patient_record,\n",
    "        semantic_regex_task=semantic_regex\n",
    "    )\n",
    "    \n",
    "    predictions.append(pred)\n",
    "    labels.append(item[\"match\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "accuracy = sum([p == l for p, l in zip(predictions, labels)]) / len(labels)\n",
    "print(f\"Accuracy: {accuracy:.2%}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alfred",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
