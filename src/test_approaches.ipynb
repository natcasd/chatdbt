{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** note you need to restart kernel in order to register changes you made to modules (approach1 and approach2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def get_dataset(dataset_string):\n",
    "  with open(dataset_string, 'r') as file:\n",
    "      data = json.load(file)\n",
    "  return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sample code to test different approaches w/ different models, also different iterations of synthetic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groq client initialized with model: llama-3.3-70b-versatile\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing records:   0%|          | 0/5 [00:00<?, ?record/s]"
     ]
    }
   ],
   "source": [
    "\n",
    "from approaches.approach1 import approach1\n",
    "from approaches.approach2 import approach2\n",
    "from llms.llm_interaction import GroqClient\n",
    "\n",
    "patient_records2 = get_dataset('datasets/patient_records2.json')\n",
    "llm_client = GroqClient(model=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "# results = approach1(patient_records2[0:5], llm_client)\n",
    "results = approach2(patient_records2[0:5], llm_client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### playing around with prompt templates and dif models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "OPENAI_API_KEY not found in environment variables",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/_7/6tgc1swx7wj1dfwwlnnj67mc0000gn/T/ipykernel_3035/4046130859.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mllms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllm_interaction\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOpenAIClient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAnthropicClient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mgpt4o\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOpenAIClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gpt-4o\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0msonnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAnthropicClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"claude-3-5-sonnet-20240620\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mversatile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGroqClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"llama-3.3-70b-versatile\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/csci2270/chatdbt/src/llms/llm_interaction.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, temperature)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mapi_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetenv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"OPENAI_API_KEY\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mapi_key\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"OPENAI_API_KEY not found in environment variables\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;31m# Initialize OpenAI client\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: OPENAI_API_KEY not found in environment variables"
     ]
    }
   ],
   "source": [
    "from llms.llm_interaction import OpenAIClient, AnthropicClient\n",
    "\n",
    "gpt4o = OpenAIClient(model=\"gpt-4o\")\n",
    "sonnet = AnthropicClient(model=\"claude-3-5-sonnet-20240620\")\n",
    "versatile = GroqClient(model=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "prompt_template = \"Check if this semantic regex - {regex} - exists in the following patient record - {record_text}.\"\n",
    "system_prompt = \"You are a helpful AI assistant that only answers True or False based on patient data and provided semantic regex matching.\"\n",
    "\n",
    "results = approach1(patient_records2[0:5], gpt4o, prompt_template=prompt_template, system_prompt=system_prompt)\n",
    "print(\"=\"*100)\n",
    "results = approach1(patient_records2[0:5], sonnet, prompt_template=prompt_template, system_prompt=system_prompt)\n",
    "print(\"=\"*100)\n",
    "results = approach1(patient_records2[0:5], versatile, prompt_template=prompt_template, system_prompt=system_prompt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## naive approach 1 (no semantic regex, just nl query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI client initialized with model: gpt-4o\n",
      "Groq client initialized with model: llama-3.3-70b-versatile\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing records: 100%|██████████| 5/5 [00:03<00:00,  1.43record/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of model over 5 generated records: 1.0\n",
      "precision of model over 5 generated records: 1.0\n",
      "recall of model over 5 generated records: 1.0\n",
      "f1 of model over 5 generated records: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing records: 100%|██████████| 5/5 [00:01<00:00,  2.64record/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of model over 5 generated records: 1.0\n",
      "precision of model over 5 generated records: 1.0\n",
      "recall of model over 5 generated records: 1.0\n",
      "f1 of model over 5 generated records: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from approaches.approach1 import approach1_naive\n",
    "from llms.llm_interaction import OpenAIClient, GroqClient\n",
    "\n",
    "gpt4o = OpenAIClient(model=\"gpt-4o\")\n",
    "versatile = GroqClient(model=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "patient_records2_nl_query = get_dataset('datasets/patient_records2_nl_query.json')\n",
    "\n",
    "results = approach1_naive(patient_records2_nl_query[0:5], gpt4o)\n",
    "# pred, true = approach1_naive(patient_records2[0:5], sonnet)\n",
    "results = approach1_naive(patient_records2_nl_query[0:5], versatile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groq client initialized with model: llama-3.3-70b-versatile\n",
      "Processing 1 records...\n",
      "\n",
      "================================================================================\n",
      "Patient Record:\n",
      "A 62-year-old former coal miner was admitted with shortness of breath, which initially presented as mild exertional dyspnea but progressively worsened over several weeks. The admission diagnosis was acute exacerbation of chronic obstructive pulmonary disease, compounded by pulmonary fibrosis likely secondary to long-standing occupational exposure to dust.\n",
      "\n",
      "The history of present illness began approximately three months prior when the patient first started noticing breathing difficulties during his daily walks. These symptoms gradually worsened, despite his efforts to manage them with over-the-counter medication. Recently, he had a fever andproductive cough, further increasing the severity of his condition.\n",
      "\n",
      "Past medical history was notable for chronic obstructive pulmonary disease, hypertension, hyperlipidemia, and lung cancer, for which he had undergone chemotherapy two years prior. Notably, the chemotherapy regimen used had included a component known to have pulmonary toxicity, which could potentially exacerbate pulmonary conditions in the long term.\n",
      "\n",
      "The patient's social history included a history of heavy smoking, approximately one and a half packs per day for over thirty years. He had also been heavily exposed to dust during his years as a coal miner and only quit recently due to declining health. Despite multiple health issues, he continued to socially drink, consuming one to two beers daily.\n",
      "\n",
      "Physical examination revealed a slightly febrile patient with a respiratory rate of 32, oxygen saturation 89% on ambient air, and significant signs of lung hyperinflation. His breath sounds were markedly decreased.\n",
      "\n",
      "Laboratory data showed a significant decline in pulmonary function, as evidenced by his PFT results. His arterial blood gas results confirmed hypoxemia, with a pO2 of 65. Blood counts revealed a neutrophilia indicative of a bacterial infection, prompting empiric antibiotic coverage.\n",
      "\n",
      "During the hospital course, the patient underwent a regimen directed towards optimizing his oxygenation, managing his infection, and adjusting his long-term respiratory management plan. This included aggressive bronchodilator and mucolytic therapy, oxygen supplementation as needed, and targeted antibiotic therapy guided by subsequent microbiology reports. He was also counseled on strict avoidance of alcohol and cigarettes to slow the deterioration of pulmonary function.\n",
      "\n",
      "Considering his exposure to chemotherapy known for pulmonary toxicity, particular attention was paid to his respiratory system, monitoring closely for signs that might indicate the exacerbation of pre-existing pulmonary issues or new complications arising from his extensive medical and occupational exposures. Upon recovery from thisacute illness, he was scheduled for intensive chest physical therapy to assist in returning him to full capacity and a plan for regular follow-up visits was laid out for the early detection of worsening symptoms or disease progression.\n",
      "\n",
      "Semantic Regex: <patient><chemotherapy><toxicity>\n",
      "response: []\n",
      "extracted_symbols: []\n",
      "\n",
      "Extracted Symbols List:\n",
      "FSM Result: Some required symbols are missing: {'patient', 'chemotherapy', 'toxicity'}\n",
      "Model prediction: False, Actual: True\n",
      "================================================================================\n",
      "accuracy of model over 1 generated records: 0.0\n",
      "precision of model over 1 generated records: 0.0\n",
      "recall of model over 1 generated records: 0.0\n",
      "f1 of model over 1 generated records: 0.0\n"
     ]
    }
   ],
   "source": [
    "from approaches.approach2 import approach2\n",
    "from llms.llm_interaction import OpenAIClient, GroqClient\n",
    "\n",
    "patient_records2 = get_dataset('datasets/patient_records2.json')\n",
    "llm_client = GroqClient(model=\"llama-3.3-70b-versatile\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1 records...\n",
      "\n",
      "================================================================================\n",
      "Patient Record:\n",
      "ADMISSION DIAGNOSIS\n",
      "The patient is a 62-year-old machinist admitted with acute kidney injury and severe anemia, likely due to complications from a recent traumatic injury. The injury occurred when the patient was involved in a car accident on his way home from work.\n",
      "\n",
      "HISTORY OF PRESENT ILLNESS\n",
      "The patient reported experiencing sudden onset abdominal pain and vomiting about six hours prior to presentation, prompting his wife to call emergency services. On route to the hospital, the patient became hypotensive but responded well to fluid resuscitation administered by paramedics. \n",
      "\n",
      "PAST MEDICAL HISTORY\n",
      "The patient has a lengthy medical history including hypertension, heart disease, hyperlipidemia, and a previous transfusion for gastrointestinal bleeding about ten years ago due to an ulcer. He takes atorvastatin and beta blockers for his cardiac condition and is known to occasionally miss taking his atenolol, leading to episodes of poorly controlled hypertension.\n",
      "\n",
      "SOCIAL HISTORY\n",
      "He is a self-retired machinist, living alone with his wife, does not smoke, has a past history of significant alcohol use but claims to consume minimally at social occasions, approximately once every 5 to 7 weeks.\n",
      "\n",
      "PHYSICAL EXAMINATION\n",
      "The patient appeared fatigued, somewhat anxious and in considerable discomfort throughout the physical exam, reporting a severe abdominal pain radiating down towards the flank, indicative of a serious renal injury. He is being treated with a broad-spectrum antibiotic after evidence was found suggestive of the onset of urosepsis, which the attending physician believed complicated his renal injury.\n",
      "\n",
      "LABORATORY DATA\n",
      "On admission his complete blood count revealed his hematocrit was at a low eighteen, white blood cell count was twenty thousand, which has significantly dropped after antibiotic treatment initiated upon admission. Creatinine was at three point three mg/dL.\n",
      "\n",
      "HOSPITAL COURSE\n",
      "Given his complex medical history including evidence of poor past renal function, it took his kidneys a longer period than generally noted to fully start the healing and regeneration of new kidney tissues post injury, as a result requiring a short course of therapy in renal recovery unit post injury healing period but has progressively improved with supportive treatment, the patient responded positively showing signs of improved vital signs throughout hospital stay but was required an extended admission due complexity in managing renal issue as part recovery and care plan included careful fluid status evaluation throughout his hospitalization with eventual resolution and preparation being made now for discharge, he will need close supervision as part the aftercare management.\n",
      "\n",
      "Semantic Regex: <patient><transfusion><transfusion_reaction>\n",
      "response: [(\"<patient>\", \"mentioned in the admission diagnosis as a 62-year-old machinist\"), (\"<transfusion>\", \"mentioned in the past medical history as a previous transfusion for gastrointestinal bleeding about ten years ago\"), (\"<transfusion_reaction>\", \"not explicitly mentioned in the patient record, however the patient had a previous transfusion and is being treated for complications, but no reaction is noted\")]\n",
      "extracted_symbols: [('<patient>', 'mentioned in the admission diagnosis as a 62-year-old machinist'), ('<transfusion>', 'mentioned in the past medical history as a previous transfusion for gastrointestinal bleeding about ten years ago'), ('<transfusion_reaction>', 'not explicitly mentioned in the patient record, however the patient had a previous transfusion and is being treated for complications, but no reaction is noted')]\n",
      "\n",
      "Extracted Symbols List:\n",
      " - ('<patient>', 'mentioned in the admission diagnosis as a 62-year-old machinist')\n",
      " - ('<transfusion>', 'mentioned in the past medical history as a previous transfusion for gastrointestinal bleeding about ten years ago')\n",
      " - ('<transfusion_reaction>', 'not explicitly mentioned in the patient record, however the patient had a previous transfusion and is being treated for complications, but no reaction is noted')\n",
      "FSM Result: Some required symbols are missing: {'patient', 'transfusion', 'transfusion_reaction'}\n",
      "Model prediction: False, Actual: False\n",
      "================================================================================\n",
      "accuracy of model over 1 generated records: 1.0\n",
      "precision of model over 1 generated records: 0.0\n",
      "recall of model over 1 generated records: 0.0\n",
      "f1 of model over 1 generated records: 0.0\n"
     ]
    }
   ],
   "source": [
    "system_prompt = \"\"\"\n",
    "        You are a helpful AI assistant that strictly outputs a python list of tuples, where each tuple is (<semantic_symbol>, explanation) in the order they appear in the patient record.\n",
    "        The output should be parseable with ast.literal_eval().\n",
    "        \"\"\"\n",
    "prompt = \"\"\"\n",
    "            Given the following patient record, extract the following semantic symbols if they exist: {regex}. \n",
    "            Return a machine parseable python list of tuples, where each tuple is (<semantic_symbol>, explanation) in the order they appear in the patient record. Only include semantic symbols that are explicitly represented in the patient record. \n",
    "            IMPORTANT: Only return the list, nothing else.\n",
    "            Make sure the order of the list reflects the order in which the semantic symbols appear in the patient record, not the order in which they are listed in the regex.\n",
    "            The explanation should be a brief description of where/how the symbol appears in the text.\n",
    "            \\n\\nPatient Record: {record_text}\n",
    "            \"\"\"\n",
    "results = approach2(patient_records2[3:4], llm_client, verbose=True, order_sensitive=True, system_prompt=system_prompt, extraction_prompt_template=prompt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
